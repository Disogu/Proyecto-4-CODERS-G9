{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "id": "40b66fc5-5da4-4799-b88b-e8923b5c988b",
      "cell_type": "code",
      "source": "# 1. Librerías\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# 2. Cargar dataset\nurl = “https://raw.githubusercontent.com/jbrownlee/Datasets/master/daily-min-temperatures.csv”\ndf = pd.read_csv(url, parse_dates=[‘Date’])\n\n# 3. Información general\ndf.info()\ndf.describe()\n\n# 4. Valores nulos\ndf.isnull().sum()\n\n# 5. Imputar o eliminar si es necesario\ndf = df.dropna()\n\n# 6. Visualización general de la serie\ndf['Temp'].plot(figsize=(14,5), title=\"Temperatura diaria en Melbourne\")\nplt.ylabel(\"Temperatura (°C)\")\nplt.show()\n\n# 7. Histogramas y boxplots\nplt.figure(figsize=(12,4))\nsns.histplot(df['Temp'], bins=50, kde=True)\nplt.title(\"Distribución de temperaturas\")\nplt.show()\n\nplt.figure(figsize=(10,3))\nsns.boxplot(x=df['Temp'])\nplt.title(\"Boxplot de temperaturas\")\nplt.show()\n\n# 8. Correlación (si hay más variables)\nif df.shape[1] > 1:\n    sns.heatmap(df.corr(), annot=True)\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "fe097c3f-e70a-44a7-a6ad-377330822880",
      "cell_type": "code",
      "source": "# 1. Librerías\nimport pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\nimport matplotlib.pyplot as plt\n\n\n# 2. Normalización\nscaler = MinMaxScaler()\ndf['Temp_scaled'] = scaler.fit_transform(df[['Temp']])\n\n# 3. Transformar en secuencias\ndef create_sequences(data, seq_length=30):\n    X, y = [], []\n    for i in range(len(data) - seq_length):\n        X.append(data[i:i+seq_length])\n        y.append(data[i+seq_length])\n    return np.array(X), np.array(y)\n\nseq_len = 30\nX, y = create_sequences(df['Temp_scaled'].values, seq_len)\n\n# 4. División train/test (80/20 temporal)\nsplit = int(len(X) * 0.8)\nX_train, y_train = X[:split], y[:split]\nX_test, y_test = X[split:], y[split:]\n\n# 5. Guardar datos\nnp.save(\"X_train.npy\", X_train)\nnp.save(\"y_train.npy\", y_train)\nnp.save(\"X_test.npy\", X_test)\nnp.save(\"y_test.npy\", y_test)\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "ce6f47b5-be66-48b9-a5e3-3d9462f75917",
      "cell_type": "code",
      "source": "# 1. Librerías\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import LSTM, Dense\nimport mlflow\nimport mlflow.tensorflow\n\n# 2. Cargar datos\nX_train = np.load(\"X_train.npy\")\ny_train = np.load(\"y_train.npy\")\nX_test = np.load(\"X_test.npy\")\ny_test = np.load(\"y_test.npy\")\n\n# 3. Construcción del modelo\nmodel = Sequential([\n    LSTM(64, input_shape=(X_train.shape[1], 1), return_sequences=False),\n    Dense(1)\n])\nmodel.compile(loss='mse', optimizer='adam', metrics=['mae'])\n\n# 4. Callback MLflow\nmlflow.tensorflow.autolog()\n\n# 5. Entrenamiento\nwith mlflow.start_run():\n    history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=20, batch_size=32)\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "129a9ae9-7afe-4937-8ef6-48778a72138f",
      "cell_type": "code",
      "source": "# 1. Librerías\nimport numpy as np\nfrom tensorflow.keras.models import load_model\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error\nimport joblib\nimport mlflow\nimport mlflow.tensorflow\n\n# 2. Cargar datos\nX_test = np.load(\"X_test.npy\")\ny_test = np.load(\"y_test.npy\")\n\n# 3. Cargar modelo (opcional si ya está entrenado)\n# model = load_model(\"lstm_model.h5\")\n\n# 4. Predicción\ny_pred = model.predict(X_test)\n\n# 5. Métricas\nmse = mean_squared_error(y_test, y_pred)\nmae = mean_absolute_error(y_test, y_pred)\nprint(\"MSE:\", mse)\nprint(\"MAE:\", mae)\n\n# 6. Exportar modelo y scaler\nmodel.save(\"lstm_model.h5\")\njoblib.dump(scaler, \"scaler.pkl\")\n\n# 7. Logging MLflow\nwith mlflow.start_run():\n    mlflow.log_param(\"model_type\", \"LSTM\")\n    mlflow.log_metric(\"MSE\", mse)\n    mlflow.log_metric(\"MAE\", mae)\n    mlflow.tensorflow.log_model(model, artifact_path=\"model\")\n    mlflow.log_artifact(\"scaler.pkl\")\n\nprint(\"Modelo y artefactos registrados con éxito en MLflow\")\n\n\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "cca3ad14-7d4a-43ff-8c78-922ca01bed0d",
      "cell_type": "code",
      "source": "",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}